{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/muhammadnadhifn/lmsys-chatbot-preference-predictions-dnn?scriptVersionId=203018137\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"Task: Classify between two given prompt on two model\n<br><br>\nDeep Neural Network Solution\n1. Bidirectional LSTM -> extract feature of prompt and respond/answer\n2. Attention Mechanism -> captures the relevance or correlation between the prompt and each response\n3. Global Pooling -> reduces the sequence of attention-weighted features while retaining the most significant information, enabling the dense layers to make a final classification.\n4. Dense/Hidden Layers -> perform the classification","metadata":{}},{"cell_type":"code","source":"import keras\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport nltk\nfrom nltk.corpus import stopwords\nfrom matplotlib import pyplot as plt","metadata":{"ExecuteTime":{"end_time":"2024-08-02T19:28:02.290117Z","start_time":"2024-08-02T19:27:57.668691Z"},"execution":{"iopub.status.busy":"2024-08-05T12:38:47.689502Z","iopub.execute_input":"2024-08-05T12:38:47.689866Z","iopub.status.idle":"2024-08-05T12:39:01.199255Z","shell.execute_reply.started":"2024-08-05T12:38:47.689834Z","shell.execute_reply":"2024-08-05T12:39:01.198468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Train Data\ndf = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n\n# Download Stopwords\n# nltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# Define Function to Remove Stopwords\ndef remove_stopwords(text):\n    words = text.split()\n    filtered_words = [word for word in words if word.lower() not in stop_words]\n    return ' '.join(filtered_words)\n\n# Parse String and Ensure all text data is encoded to UTF-8\nfor col in [i for i in df.columns if i in ['prompt', 'response_a', 'response_b']]:\n    df[col] = df[col].map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n    df[col] = df[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8'))\n    # Lower Text\n    df[col] = df[col].str.lower()\n    # Remove Punctuation\n    df[col] = df[col].str.replace(r'[^\\w\\s]', '', regex=True)\n    # Remove Stopwords\n    df[col] = df[col].apply(remove_stopwords)\n\n# Show Sample\ndf.head()","metadata":{"ExecuteTime":{"end_time":"2024-08-02T19:28:13.027087Z","start_time":"2024-08-02T19:28:02.292446Z"},"execution":{"iopub.status.busy":"2024-08-05T12:39:01.200821Z","iopub.execute_input":"2024-08-05T12:39:01.201332Z","iopub.status.idle":"2024-08-05T12:39:21.280633Z","shell.execute_reply.started":"2024-08-05T12:39:01.201295Z","shell.execute_reply":"2024-08-05T12:39:21.279727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create label dictionary for mapping\nlabel_map = {'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2}\n\n# Map column into label\ndf['label'] = df[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1).map(label_map)","metadata":{"ExecuteTime":{"end_time":"2024-08-02T19:28:13.047364Z","start_time":"2024-08-02T19:28:13.028743Z"},"execution":{"iopub.status.busy":"2024-08-05T12:39:21.281667Z","iopub.execute_input":"2024-08-05T12:39:21.281979Z","iopub.status.idle":"2024-08-05T12:39:21.313421Z","shell.execute_reply.started":"2024-08-05T12:39:21.281941Z","shell.execute_reply":"2024-08-05T12:39:21.312616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenizer\ntokenizer = Tokenizer()\ntexts = df['prompt'].tolist() + df['response_a'].tolist() + df['response_b'].tolist()\ntokenizer.fit_on_texts(texts)","metadata":{"ExecuteTime":{"end_time":"2024-08-02T19:28:21.790065Z","start_time":"2024-08-02T19:28:13.050442Z"},"execution":{"iopub.status.busy":"2024-08-05T12:39:21.314658Z","iopub.execute_input":"2024-08-05T12:39:21.314956Z","iopub.status.idle":"2024-08-05T12:39:35.694535Z","shell.execute_reply.started":"2024-08-05T12:39:21.314922Z","shell.execute_reply":"2024-08-05T12:39:35.693647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_fn(prompt, response_a, response_b, label=None):\n    prompt = pad_sequences(tokenizer.texts_to_sequences(prompt), maxlen=512, padding='post', truncating='post')\n    response_a = pad_sequences(tokenizer.texts_to_sequences(response_a), maxlen=512, padding='post', truncating='post')\n    response_b = pad_sequences(tokenizer.texts_to_sequences(response_b), maxlen=512, padding='post', truncating='post')\n    feature = {\n        'prompt': prompt,\n        'response_a': response_a,\n        'response_b': response_b\n    }\n    return (feature, label) if label is not None else feature\n\ndef build_dataset(prompt, response_a, response_b, label=None, batch_size=1, shuffle=True):\n    slices = (preprocess_fn(prompt, response_a, response_b, label))\n    ds = tf.data.Dataset.from_tensor_slices(slices)\n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(prompt))\n    ds = ds.batch(batch_size=batch_size)\n    return ds","metadata":{"ExecuteTime":{"end_time":"2024-08-02T23:49:35.870692Z","start_time":"2024-08-02T23:49:35.864847Z"},"execution":{"iopub.status.busy":"2024-08-05T12:39:35.696763Z","iopub.execute_input":"2024-08-05T12:39:35.697075Z","iopub.status.idle":"2024-08-05T12:39:35.704999Z","shell.execute_reply.started":"2024-08-05T12:39:35.697049Z","shell.execute_reply":"2024-08-05T12:39:35.704078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.2, stratify=df.label)\n\ntrain_ds = build_dataset(\n    prompt=train_df.prompt.values.tolist(),\n    response_a=train_df.response_a.values.tolist(),\n    response_b=train_df.response_b.values.tolist(),\n    label=train_df.label.values.tolist(),\n    batch_size=32,\n    shuffle=True\n)\n\nval_ds = build_dataset(\n    prompt=val_df.prompt.values.tolist(),\n    response_a=val_df.response_a.values.tolist(),\n    response_b=val_df.response_b.values.tolist(),\n    label=val_df.label.values.tolist(),\n    batch_size=32,\n    shuffle=False\n)","metadata":{"ExecuteTime":{"end_time":"2024-08-02T23:49:43.10309Z","start_time":"2024-08-02T23:49:36.056996Z"},"execution":{"iopub.status.busy":"2024-08-05T12:39:35.706016Z","iopub.execute_input":"2024-08-05T12:39:35.706369Z","iopub.status.idle":"2024-08-05T12:39:48.429989Z","shell.execute_reply.started":"2024-08-05T12:39:35.706329Z","shell.execute_reply":"2024-08-05T12:39:48.428966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspect the dataset\nfor feature, label in train_ds:\n    print(f\"Feature 1: {feature['prompt'].numpy().shape}, Feature 2: {feature['response_a'].numpy().shape}, Feature 3: {feature['response_b'].numpy().shape}, Label: {label.numpy().shape}\")\n    break","metadata":{"ExecuteTime":{"end_time":"2024-08-02T23:49:03.043002Z","start_time":"2024-08-02T23:49:02.463312Z"},"execution":{"iopub.status.busy":"2024-08-05T12:39:48.431161Z","iopub.execute_input":"2024-08-05T12:39:48.431459Z","iopub.status.idle":"2024-08-05T12:39:48.766911Z","shell.execute_reply.started":"2024-08-05T12:39:48.431434Z","shell.execute_reply":"2024-08-05T12:39:48.765878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define input layers with integer-encoded sequences\nprompt_input = tf.keras.Input(shape=(512,), name='prompt')\nresponse_a_input = tf.keras.Input(shape=(512,), name='response_a')\nresponse_b_input = tf.keras.Input(shape=(512,), name='response_b')\n\n# Reshape inputs to (batch_size, sequence_length, 1) for LSTM\nprompt_reshaped = layers.Reshape((512, 1))(prompt_input)\nresponse_a_reshaped = layers.Reshape((512, 1))(response_a_input)\nresponse_b_reshaped = layers.Reshape((512, 1))(response_b_input)\n\n# Define LSTM layer\nbi_lstm = layers.Bidirectional(layers.LSTM(100, return_sequences=True))\n\n# Apply LSTM to reshaped inputs\nprompt_encoded = bi_lstm(prompt_reshaped)\nresponse_a_encoded = bi_lstm(response_a_reshaped)\nresponse_b_encoded = bi_lstm(response_b_reshaped)\n\nattention_a = layers.Attention()([prompt_encoded, response_a_encoded])\nattention_b = layers.Attention()([prompt_encoded, response_b_encoded])\n\npool_a = layers.GlobalAveragePooling1D()(attention_a)\npool_b = layers.GlobalAveragePooling1D()(attention_b)\n\n# Concatenate encoded outputs\nx = layers.Concatenate()([pool_a, pool_b])\nx = layers.Dense(256, activation='relu')(x)\nx = layers.Dense(64, activation='relu')(x)\nx = layers.Dense(8, activation='relu')(x)\n\n# Output layer\noutputs = layers.Dense(3, activation='softmax')(x)\n\n# Build and compile the model\nmodel = tf.keras.Model(inputs=[prompt_input, response_a_input, response_b_input], outputs=outputs)\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\nmodel.compile(\n    optimizer=optimizer,\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    metrics=[\"accuracy\"],\n)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T13:11:20.011369Z","iopub.execute_input":"2024-08-05T13:11:20.012139Z","iopub.status.idle":"2024-08-05T13:11:20.165352Z","shell.execute_reply.started":"2024-08-05T13:11:20.012105Z","shell.execute_reply":"2024-08-05T13:11:20.164535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=128, callbacks=[early_stopping])","metadata":{"ExecuteTime":{"end_time":"2024-08-02T23:39:04.450943Z","start_time":"2024-08-02T23:37:09.239453Z"},"execution":{"iopub.status.busy":"2024-08-05T13:11:30.425311Z","iopub.execute_input":"2024-08-05T13:11:30.425895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation loss\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss over epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2024-08-02T23:39:04.5937Z","start_time":"2024-08-02T23:39:04.453276Z"},"execution":{"iopub.status.busy":"2024-08-05T12:39:50.049425Z","iopub.status.idle":"2024-08-05T12:39:50.049907Z","shell.execute_reply.started":"2024-08-05T12:39:50.049655Z","shell.execute_reply":"2024-08-05T12:39:50.049674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Test Data\ntest_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n\n# Parse String and Ensure all text data is encoded to UTF-8\nfor col in [i for i in df.columns if i in ['prompt', 'response_a', 'response_b']]:\n    test_df[col] = test_df[col].map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n    test_df[col] = test_df[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8'))\n    # Lower Text\n    test_df[col] = test_df[col].str.lower()\n    # Remove Punctuation\n    test_df[col] = test_df[col].str.replace(r'[^\\w\\s]', '', regex=True)\n    # Remove Stopwords\n    test_df[col] = test_df[col].apply(remove_stopwords)\n\n# Show Sample\ntest_df.head()","metadata":{"ExecuteTime":{"end_time":"2024-08-02T23:46:29.646132Z","start_time":"2024-08-02T23:46:29.597159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = build_dataset(\n    prompt=test_df.prompt.values.tolist(),\n    response_a=test_df.response_a.values.tolist(),\n    response_b=test_df.response_b.values.tolist(),\n    batch_size=32,\n    shuffle=False\n)","metadata":{"ExecuteTime":{"end_time":"2024-08-02T23:47:43.598266Z","start_time":"2024-08-02T23:47:43.580294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = model.predict(test_ds)","metadata":{"ExecuteTime":{"end_time":"2024-08-02T23:47:44.987135Z","start_time":"2024-08-02T23:47:44.159448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = test_df[[\"id\"]].copy()\nsubmission_df[['winner_model_a', 'winner_model_b', 'winner_tie']] = test_pred.tolist()\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df.head()","metadata":{"ExecuteTime":{"end_time":"2024-08-02T23:47:45.02625Z","start_time":"2024-08-02T23:47:44.989582Z"},"trusted":true},"execution_count":null,"outputs":[]}]}